# Context sensitive help texts
# The property key has three sections 
# 1) The area, like 'jobs' or 'transformations' or 'settings' (for instance taken from 
#    web app path)
# 2) The section of a page, like 'general information' or 'oai-pmh specific information',
#    probably taken from the application page itself
# 3) The label of the field to provide help for, like 'service provider', taken from the page
#
# When constructing a property name from a field label, use underscores for spaces and 
# omit any colons or equal signs from the property name.
#
# For example:  
# Field label in General Information section: "Encoding override (ISO-8859-1, UTF-8, ...):"
# Use property name   jobs.General_information.Encoding_override_(ISO-8859-1,_UTF-8,_...)
#
# Reference this help text from UI code as:
# <id:helplink field="[jobs][General information][Encoding override (ISO-8859-1, UTF-8, ...)]"/>
# Or alternatively as: 
# <id:helplink area="jobs" section="General information" label="Encoding override (ISO-8859-1, UTF-8, ...)"/>
# 
#

jobs.General_information.Id   =  Automatically assigned identifier for the job

jobs.General_information.Name =  Preferably a unique name for users to identify this Harvester \
                resource. In some cases the name may be proposed after filling \
                out protocol specific section of the configuration (e.g Index \
                Data Connectors, OAI-PMH).

jobs.General_information.Service_Provider = Free-text field used by support staff for \
                           recording administrative information.<br/> Not used by the harvester.

jobs.General_information.Content_Description = Free-text field used by support staff \
                              for recording administrative information. Not used by the harvester.

jobs.General_information.Technical_Notes =  Free-text field used by support staff for \
                           recording administrative information. Not used by the harvester.

jobs.General_information.Contact_Notes = Free-text field used by support staff for recording \
                        administrative information. Not used by the harvester.

jobs.General_information.Harvest_job_enabled = Check to run the Harvesting job as described by the \
                              time/interval selected in "Harvest schedule". Leaving this \
                              box unchecked will make the job inactive.

jobs.General_information.Harvest_schedule = Use these fields to define a recurring time/interval at \
                                            which the Harvester job should run. E.g \
                                            for weekly runs specify a day of the week on which the harvest \
                                            should be executed.

jobs.General_information.Transformation_Pipeline = Select the transformation required to match the input \
                              format delivered by the feed to the internal format used by the Harvester for \
                              data storage. See the Transformation Pipelines manual section for more details.

jobs.General_information.Use_lax_parsing_(if_possible) = When enabled, harvester will attempt to parse malformed XML \
                                           (missing closing tags, entities)

jobs.General_information.Encoding_override_(ISO-8859-1,_UTF-8,_...) = A feed can return invalid encoded responses, such as \
                               having an XML header with encoding set to UTF-8, but actually return ISO-8859-1 in \
                               the data. Setting this field to the actual encoding will force the Harvester to use \
                               the specified encoding.

jobs.General_information.Storage = Select the storage type and location for the harvested data. The Harvester \
                               has a storage abstraction layer to allow it to work with multiple potential \
                               record storage systems, but at present, only Solr/Lucene is supported. <br/><br/>Once \
                               the Storage has been selected, it is possible to view the indexed records by \
                               clicking the Stored records: click to view field.

jobs.General_information.Stored_records = Follow this link to view previously indexed records from the chosen Storage.

jobs.General_information.Cache_on_disk = If enabled, harvest data is kept in the filesystem cache and the job \
                               can be restarted from this cache without needing to go back to the server. 

jobs.General_information.Limit_record_number_to = Limit the harvest run to a specified number of records: \
                               useful for testing job settings and transformation pipelines.

jobs.General_information.Connection/read_timeout_(seconds) = Specify a non-default timeout value for obtaining and \
                               reading from the network connection (socket). Values under 1 minute are not \
                               recommended.

jobs.General_information.Log_level = Specify the logging level for the job with DEBUG being the most verbose. \
                               INFO is the recommended log level in most cases.

jobs.General_information.Notification_e-mail_address(es)_(separate_with_comma) = Specify comma separated list of e-mail addresses that \
                               should receive notification on job completion.

jobs.General_information.Extra_configuration_(JSON) = Specify additional advanced harvester configuration in the \
                               JSON format.

jobs.General_information.Send_notification_if_severity_at_least = specify job completion status with the least \
                               severity that will trigger the e-mail notification.


jobs.OAI-PMH_specific_information.OAI_Repository_URL = Enter a link (http-based) to the resource to be harvested. \
                               Include the base link defined by OAI Set Name: (see below). Some resources have \
                               multiple sets within the repository. If no specific set is identified by the URL, \
                               the full repository will be harvested.

jobs.OAI-PMH_specific_information.OAI_Set_Name_(type_for_suggestions) = an optional setting, an OAI-PMH setSpec value which \
                               specifies set criteria for selective harvesting.

jobs.OAI-PMH_specific_information.Metadata_Prefix = A string that specifies the metadata format in OAI-PMH requests \
                               issued to a targeted repository. It is important to choose the correct format or no \
                               data will be harvested from the repository. Make sure a Transformation Pipeline that \
                               matches the metadata format used in the repository is selected, otherwise records \
                               will not be understood by the Harvester. Repositories generally use one of the \
                               following prefixes (or embedded data formats): Dublin Core (OAI-DC) or MARC XML \
                               (MARC12/USMARC). Other less common MetadataPrefix values include PMC (PubMed Central \
                               full-text records), PMC (PubMed Central metadata records), and PZ2 (pazpar2).

jobs.OAI-PMH_specific_information.Use_long_date_format = Check-box to indicate whether to use a long date format when \
                               requesting records from the OAI-PMH resource. This is not used very often, but is \
                               required by some resources.

jobs.OAI-PMH_specific_information.Harvest_from_(yyyy-MM-dd) = If empty and no resumption token is set, the Harvester \
                               will harvest the full data set from the resource. When this field contains a value, \
                               upon completion of the job the Harvester will reset the value of this field to the day \
                               prior to the current run date, so subsequent runs will harvest only new records.

jobs.OAI-PMH_specific_information.Harvest_until_(yyyy-MM-dd) = Upper date limit for selective harvesting. On consecutive \
                               runs the Harvester will clear this field making the date interval open-ended.

jobs.OAI-PMH_specific_information.Resumption_token_(overrides_date) = The OAI-PMH protocol supports splitting bigger \
                               datasets into smaller chunks. On delivery of a chunk of records, the OAI-PMH returns a \
                               token which the next request should use in order to get the next chunk. If an OAI-PMH \
                               job halts before completion, the resumption token will be set in this field. Sometimes \
                               it is possible to run it again from this resumption point at a later stage, but this \
                               is not always supported.

jobs.OAI-PMH_specific_information.Clear_resumption_token_on_connection_errors = Clear the resumption token for \
                               harvests that complete in an error state. This is useful when server errors out and \
                               the last resumption token is no longer valid.

jobs.OAI-PMH_specific_information.Keep_partial_harvests = When checked, partial records harvested during a failed \
                               harvest run will be retained in storage.

jobs.OAI-PMH_specific_information.Request_retry_count = Specify how many times the harvester should retry failed \
                               harvest requests, 0 disables retrying entirely.

jobs.OAI-PMH_specific_information.Delay_before_retry_(seconds) = Delay for retrying failed requests. Only change \
                               when resource fails to work with the default values.

jobs.XML_bulk_specific_information.URLs_(space-separated) = One or more space-separated URL (HTTP or FTP) for XML \
                               or MARC binary data. Jump or index pages (HTML pages with URLs) are supported and \
                               so are FTP directories. For FTP, harvesting of recursive directories may be enabled below.

jobs.XML_bulk_specific_information.Continue_on_errors = Check to continue harvesting and storing records even if \
                               retrieving some of the listed resources fails.

jobs.XML_bulk_specific_information.Overwrite_data_with_each_run_(non-incremental) = Check to delete all previously \
                               harvested data before beginning the next scheduled (or manually triggered) run. This \
                               may be used when complete catalog dumps reside on the server.

jobs.XML_bulk_specific_information.Ask_server_for_new_files_only_(incremental) = Ask the server if the files are \
                               modified before attempting a harvest, relies on proper timestamp handling on the \
                               server side. It\u2019s usually safe to have this enabled as servers are eager to \
                               update the modification date, even in cases when the files themselves don\u2019t \
                               change. Enabling this setting may significantly shorten harvest times.

jobs.XML_bulk_specific_information.Split_XML_at_depth_(zero/empty_disables_split) = For XML data. This should \
                               usually be set to 1 for XML feeds, if we want to harvest the record elements in \
                               the data structured like:<br/><br/>\
                               &lt;root&gt;<br/>&nbsp;&lt;record/&gt;<br/>&nbsp;&lt;record/&gt;<br/>&lt;/root&gt;

jobs.XML_bulk_specific_information.Split_files_at_number_of_records_(zero/empty_disables_split) = The Harvester \
                               tries to imply streaming parsing where possible, but many XSL Transformations \
                               will not support this. Attempting to transform millions of records will be too \
                               memory consuming, so breaking the resource into chunks of 1000 records seems to \
                               be a reasonable option. Enter into this field the number of records to be \
                               contained in each chunk.

jobs.XML_bulk_specific_information.Mime-type_override_(e.g_application/marc;_charsetMARC-8) = The Harvester detects \
                               the type (XML vs MARC binary) from the MIME-type and file extension. It is also able \
                               to deal with compressed archives (zip, tar, gzip), in some rare case it may be \
                               required to provide the content type manually (e.g if it\u2019s missing or wrong), \
                               the format is:<br/><br/>\
                               MIME-type [; optional character encoding].

jobs.XML_bulk_specific_information.MARC_XML_transformation_format_(application/marc_or_application/tmarc) =  This field \
                               expresses the output format of binary MARC reading\u2013which will also be the input \
                               format for the transformation pipeline. If the Transformation Pipeline expects MARC21 \
                               XML, this should be set to Application/marc. If the pipeline expects Turbo MARC XML, \
                               it should be set to Application/tmarc.

jobs.XML_bulk_specific_information.Recurse_into_subfolders = When set, the harvester will traverse the entire directory \
                               tree and search for harvestable files. This setting should be enabled with care.

jobs.XML_bulk_specific_information.Use_passive_mode_for_FTP_transfers = When set passive, instead of active, mode is \
                               used for FTP connections. If harvester is running within a restricted firewall that \
                               blocks FTP active mode connections, enabling this setting might help. It might be, \
                               however, necessary to align this mode with what FTP server expects.

TODO list

Big questions
* Harvesting (or ingesting) other types. XML files? web crawler?

OAI Harvester:

* OAI repositories
    - Some reauire longer time stamps (instead of the YYYY-MM-DD).
    - What if they require/support other data types than oai_dc? 
      What can we index and search?

* How to handle duplicates (is there a need to handle them?) 
    - if record gets updated do we need to find and remove the old one? 
    - Do the records have unique IDs?  

* Zebra configuration
    - Database name
       - from users or (more likely) generated from the oai url+setname
       - Needs to be known to the admin part, so it can search it
    - Zebra port number etc? Hard coded/config

* Harvester configuration 
    - Where to keep the config, how to edit it (at install time). (web.xml?)
    - Settings 
       - Our own base URL.
       - Location of the admin WS
       - How often to check harvest job status

* Harvester reporting itself to the admin
    - After installing, the harvester should tell the admin that
       - it is available
       - its address
       - its Z-address for searching (or is this by job)
       
* Error handling in the harvester, passing errors up to the admin
    - Hard errors that terminate the job
    - Soft errors that result in skipping some records
    - Temporary errors that make the harvester wait and retry in a while
    - Reporting progress to the admin
    - Reporting number of soft errors to the admin
      (especially relevant if all (or most) of the records end as soft errors)
    - The NoRecordsMatch error is not an error at all, it is quite usual
      situation that no records were added in the last day.

* Cleaning up when the job gets killed/removed
   - Pretty much done. We delete the files, and drop the zebra database.


Admin interface

* Add a flag to request purging the database before harvesting it
* Add a flag to harvest immediately, no matter what the timing says


